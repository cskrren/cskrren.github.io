---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a first-year PhD candidate jointly supervised by Shanghai Jiao Tong University and Shanghai Artificial Intelligence Laboratory, under the primary guidance of Dr. Daibo. Currently, I am also a research intern at the Embodied AI Center of Shanghai AI Lab, co-advised by Dr. Mulin Yu and Dr. Linning Xu. Prior to my doctoral studies, I received my Bachelor of Engineering degree from Tongji University, where I conducted research on HDR reconstruction for dynamic scenes under the supervision of Prof. Zhangkai Ni.

My research interests lie in 3D reconstruction, neural rendering, and scene relighting. I have published papers in top-tier computer vision conferences and journals including CVPR, RSS, TPAMI, and IJCV, with my publications accumulating <a href='https://scholar.google.com/citations?user=5kW5apkAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a> Google Scholar citations.

# üî• News
- *2025.06*: &nbsp;üéâ Our SMHDR on Multi-view HDR Reconstruction was accepted to IJCV 2025.
- *2025.05*: &nbsp;üéâ Our Octree-GS on LOD-Structured 3D Gaussians was accepted to TPAMI 2025.
- *2025.04*: &nbsp;üéâ One paper on One-Shot Manipulation (code) was accepted to RSS 2025.
- *2025.02*: &nbsp;üéâ Our Horizon-GS on Aerial-to-Ground Scene Reconstruction was accepted to CVPR 2025.
- *2024.07*: &nbsp;üéì Graduated from Tongji University.

# üìù Publications 

(‚Ä†: corresponding author; * :equal contribution)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv 2025</div><img src='images/AnySplat.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views](https://arxiv.org/abs/2505.23716)

Lihan Jiang, Yucheng Mao, Linning Xu, Tao Lu, **Kerui Ren**, Yichen Jin, Xudong Xu, Mulin Yu, Jiangmiao Pang, Feng Zhao, Dahua Lin, Bo Dai

[**Project**](https://city-super.github.io/anysplat/)
- We introduce AnySplat, a feed‚Äëforward network for novel‚Äëview synthesis from uncalibrated image collections in both sparse‚Äë and dense‚Äëview scenarios.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv 2025</div><img src='images/MVCoLight.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MV-CoLight: Efficient Object Compositing with Consistent Lighting and Shadow Generation](https://arxiv.org/abs/2505.21483)

**Kerui Ren**, Jiayang Bai, Linning Xu, Lihan Jiang, Jiangmiao Pang, Mulin Yu, Bo Dai

[**Project**](https://city-super.github.io/mvcolight/)
- We introduce MV-CoLight, a two-stage framework for illumination-consistent object compositing in both 2D images and 3D scenes.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv 2025</div><img src='images/HaloGS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[HaloGS: Loose Coupling of Compact Geometry and Gaussian Splats for 3D Scenes](https://arxiv.org/abs/2505.20267)

Changjian Jiang*, **Kerui Ren\***, Linning Xu, Jiong Chen, Jiangmiao Pang, Yu Zhang, Bo Dai, Mulin Yu‚Ä†

[**Project**](https://city-super.github.io/halogs/) 
- We introduce HaloGS, a dual-representation that loosely couples triangles for geometry with Gaussians for appearance, enabling high-fidelity rendering with compact geometry.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RSS 2025</div><img src='images/RoboSplat.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation](https://www.roboticsproceedings.org/rss21/p146.pdf)

Sizhe Yang*, Wenye Yu*, Jia Zeng, Jun Lv, **Kerui Ren**, Cewu Lu, Dahua Lin, Jiangmiao Pang‚Ä†

[**Project**](https://yangsizhe.github.io/robosplat/) [**Code**](https://github.com/OpenRobotLab/RoboSplat) <strong><span class='show_paper_citations' data='5kW5apkAAAAJ:2osOgNQ5qMEC'></span></strong>
- We introduce RoboSplat, which leverages 3D Gaussian Splatting to generate realistic, diverse training demonstrations from a single expert demo and multi-view images, enabling RGB-based policies to robustly generalize across object poses/types, camera views, scene appearance, lighting, and robot embodiments while outperforming 2D augmentation methods in a unified framework.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/HorizonGS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Horizon-GS: Unified 3D Gaussian Splatting for Large-Scale Aerial-to-Ground Scenes](https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Horizon-GS_Unified_3D_Gaussian_Splatting_for_Large-Scale_Aerial-to-Ground_Scenes_CVPR_2025_paper.html)

Lihan Jiang*, **Kerui Ren\***, Mulin Yu, Linning Xu, Junting Dong, Tao Lu, Feng Zhao, Dahua Lin, Bo Dai‚Ä†

[**Project**](https://city-super.github.io/horizon-gs/) [**Code**](https://github.com/OpenRobotLab/HorizonGS) <strong><span class='show_paper_citations' data='5kW5apkAAAAJ:9yKSN-GCB0IC'></span></strong>
- We introduce Horizon-GS, tackles the unified reconstruction and rendering for aerial and street views with a new training strategy, overcoming viewpoint discrepancies to generate high-fidelity scenes.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv 2025</div><img src='images/BootStrap.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Bootstrap-GS: Self-Supervised Augmentation for High-Fidelity Gaussian Splatting](https://arxiv.org/abs/2404.18669)

Yifei Gao*, **Kerui Ren\***, Jie Ou, Lei Wang, Jiaji Wu, Jun Cheng

[**Code**](https://github.com/yileijin/Bootstrap-GS)
- We introduce a bootstrapping framework that generates pseudo-ground truth data from novel viewpoints compatible with the original training set and feeds it back into training, which reduces artifacts, improves metrics, and is adaptable to other Gaussian-based methods.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv 2025</div><img src='images/PayAtten.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Pay Attention to What You Need](https://arxiv.org/abs/2307.13365)

Yifei Gao, Shaohong Chen, Lei Wang, Ruiting Dai, Ziyun Zhang, **Kerui Ren**, Jiaji Wu, Jun Cheng

[**Code**](https://github.com/yileijin/PayAttn)
- We propose Scaled ReAttention (SRA), a lightweight method that boosts LLMs' long-context understanding without fine-tuning or retraining.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2025</div><img src='images/OctreeGS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians](https://ieeexplore.ieee.org/document/10993308)

**Kerui Ren\***, Lihan Jiang*, Tao Lu, Mulin Yu, Linning Xu, Zhangkai Ni, Bo Dai‚Ä†

[**Project**](https://city-super.github.io/octree-gs/) [**Code**](https://github.com/city-super/Octree-GS) <strong><span class='show_paper_citations' data='5kW5apkAAAAJ:u5HHmVD_uO8C'></span></strong>
- We introduce Octree-GS, featuring an LOD-structured 3D Gaussian approach supporting level-of-detail decomposition for scene representation that contributes to the final rendering results.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2025</div><img src='images/SMHDR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Semantic Masking with Curriculum Learning for Robust HDR Image Reconstruction](https://link.springer.com/article/10.1007/s11263-025-02504-5?utm_source=rct_congratemailt)

Zhangkai Ni, Yang Zhang, **Kerui Ren**, Wenhan Yang‚Ä†, Hanli Wang‚Ä†, Sam Kwong

[**Code**](https://github.com/eezkni/SMHDR)
- We propose a novel SAM-guided MIM for HDR reconstruction (SMHDR). The combination of curriculum learning strategy and masked image modeling bridges the gap between pixel fitting and semantic understanding, which successfully turns the knowledge of SAM into the intrinsic understanding of the quality issues of HDR images.
</div>
</div>

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2024.09 - present*, Ph.D. in Information and Communication Engineering, Shanghai Jiao Tong University
- *20W0.09 - 2024.07*, B.S. in Computer Science and Technology, Tongji University

# üí¨ Community Services

Reviewer

- SIGGRAPH Asia 25

# üíª Internships
- *2023.11 - present*, [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/), Shanghai, China.